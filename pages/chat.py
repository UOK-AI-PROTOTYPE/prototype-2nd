import streamlit as st
from openai import OpenAI
from streamlit_chat import message
from utils import modal
from intro import set_intro
import toml, json

setting = toml.load('setting.toml')
prompts = toml.load('prompts.toml')

st.set_page_config(
    initial_sidebar_state="collapsed",
    page_title="UOK AI PROJECT",
    page_icon="ğŸ¤–",
    layout="centered",
)

# set_navbar()
# chat_background()
# with st.sidebar:
#     st.image(logos, width=70)
#     st.write(prompts["sidebar_script"])

st.title("UOK ì„±í–¥ ì¶”ë¡  ì±—ë´‡")
st.write("ì±—ë´‡ê³¼ì˜ ëŒ€í™”ë¥¼ í†µí•´ ì‚¬ìš©ìì˜ ì„±í–¥ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ë°”ë¡œ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë³´ì„¸ìš”!")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = setting["openai_model"]

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": prompts["setting_prompt"]}
    ]
    modal.enter_modal()

if 'target_name' in st.session_state and 'num_participant' in st.session_state:
    target_name = st.session_state['target_name'] # ë¶„ì„ëŒ€ìƒ ì´ë¦„
    num_participant = st.session_state['num_participant'] # ì´ ì°¸ì—¬ì ìˆ˜

    # ì²«ë²ˆì§¸ ì§ˆë¬¸ (í•˜ë“œì½”ë”©)
    first_question = f"""ì•ˆë…•í•˜ì„¸ìš”, {target_name}ë‹˜.
    ì´ {num_participant}ë¶„ì´ MBTIë¶„ì„ì— ì°¸ì—¬í•˜ì‹œëŠ”êµ°ìš”.:)  
    ì²«ë²ˆì§¸ ì§ˆë¬¸ë“œë¦¬ê² ìŠµë‹ˆë‹¤.  
    ë³¸ì¸ê³¼ ê°€ì¥ ì…©ê²©ì´ë‚˜ í–‰ë™ì´ ë¹„ìŠ·í•œ ì˜í™” ìºë¦­í„°ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ê·¸ ì´ìœ ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”."""

    # ì²«ë²ˆì§¸ ì§ˆë¬¸ messagesì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": first_question})
    print(st.session_state.messages)


for message in st.session_state.messages[1:]:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])            

if prompt := st.chat_input("ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš” !"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=st.session_state["openai_model"],
            max_tokens=1000, # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
            temperature = 1,  # ë‹¤ì–‘ì„± ì¡°ì ˆì„ ìœ„í•œ ì˜¨ë„ ë§¤ê°œë³€ìˆ˜
            presence_penalty= 1.5, # ê°’ì´ í´ìˆ˜ë¡ ìƒˆë¡œìš´ ì£¼ì œì— ëŒ€í•´ ì´ì•¼ê¸°
            messages=[ 
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        )
        response = st.write_stream(stream)
    st.session_state.messages.append({"role": "assistant", "content": response})
